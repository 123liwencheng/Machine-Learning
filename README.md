# Machine-Learning
House-Price：一个线性回归模型，使用梯度下降算法来优化模型参数。
以下是算法的详细说明：

### 算法步骤

1. **数据加载与预处理**:
   - 使用 `pandas` 加载数据集，并将特征和目标变量分开。
   - 对特征进行归一化处理，使其值在 [0, 1] 范围内，以提高模型训练的稳定性和收敛速度。

2. **添加偏置项**:
   - 在特征矩阵 `X` 中添加一列全为1的偏置项，以便在模型中包含截距（bias）。

3. **初始化参数**:
   - 初始化权重（weights）为零，偏置（bias）也初始化为零。这是梯度下降算法的起始点。

4. **损失函数**:
   - 定义均方误差（MSE）作为损失函数，计算模型预测值与实际值之间的差异。

5. **梯度下降**:
   - 在 `gradient_descent` 函数中，使用梯度下降算法迭代更新权重和偏置。每次迭代的步骤如下：
     - 计算当前的预测值。
     - 计算预测值与实际值之间的误差。
     - 计算权重的更新量。
     - 更新偏置。

6. **模型预测**:
   - 使用训练好的权重和偏置进行预测，计算预测值。

7. **结果可视化**:
   - 绘制实际房价与预测房价的散点图，并添加参考线，以便直观比较模型的预测效果。

      
sin(x):通过反向传播优化五次多项式的系数，以拟合正弦函数。
以下是算法的详细说明：

### 算法步骤

1. **数据生成**:
   - 使用 `numpy` 生成 `data_count` 个数据点，范围从 `0` 到 `2π`，并存储在数组 `x` 中。

2. **初始化参数**:
   - 定义一个包含五次多项式系数的数组 `param`，初始值为 `[0, 1, 0, -1/6, 0, 1/120]`，这些系数对应于多项式的各项。

3. **定义多项式函数**:
   - `function_sin(xx, param)` 函数计算给定 `xx` 值的五次多项式值，使用 `param` 中的系数。

4. **定义损失函数**:
   - `loss_function(param)` 计算当前多项式与正弦函数之间的均方误差（MSE）。损失函数的值越小，表示多项式拟合的效果越好。

5. **计算偏导数**:
   - `partial_derivative(j, param)` 计算损失函数对每个参数的偏导数。这个偏导数用于确定如何调整参数以减少损失。

6. **反向传播更新参数**:
   - 在多个训练轮（`epochs`）中，程序会根据不同的 `x` 值范围进行训练。
   - 在每个训练轮中，进行多次迭代（`times_per_epoch`），在每次迭代中：
     - 计算当前的损失值。
     - 对每个参数，使用学习率和对应的偏导数更新参数。
     - 如果当前损失小于之前的最小损失，更新最小损失值和最优参数。如果损失增加，则恢复到之前的最优参数，并减小学习率。

7. **动态调整学习率**:
   - 如果损失函数的改进小于某个阈值（0.01），则增加学习率，以加快收敛速度。
   - 如果损失函数发散（增加），则恢复到之前的最优参数，并减小学习率，以避免进一步的发散。

8. **结果可视化**:
   - 最后，程序绘制实际的正弦函数值和拟合的多项式值，以便直观地比较拟合效果。
